{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1f65e174391277f634e70871feaa21300658cb740b5dabfc689c4c43dbc10e3e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Implementación del método de la máxima verosimilitud para la regresión logística\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Definir la función de entorno $L(\\beta)$\n",
    "$$\\large{L(\\beta) = \\prod_{i=1}^n}P_i^{y_i}(1-P_i)^{1-y_i}$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood (y, pi):\n",
    "    import numpy as np\n",
    "    total_prod = 1\n",
    "    for i in range(len(y)):\n",
    "        prod_in = np.where(y[i]==1,pi[i],1-pi[i])\n",
    "        total_prod = total_prod*prod_in\n",
    "    return total_prod"
   ]
  },
  {
   "source": [
    "### Calcular las probabilidades para cada observación\n",
    "$$\\large{P_i = P(x_i) = \\frac{1}{1+e^{-(\\beta \\cdot x_1)}}}$$\n",
    "Recordar que $\\alpha = \\beta_0$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logitprobs(X,beta):\r\n",
    "    import numpy as np\r\n",
    "    n_rows = np.shape(X)[0]\r\n",
    "    n_cols = np.shape(X)[1]\r\n",
    "    pi=list(range(1,n_rows+1))\r\n",
    "    expon=list(range(1,n_rows+1))\r\n",
    "    for i in range(n_rows):\r\n",
    "        expon[i] = 0\r\n",
    "        for j in range(n_cols):\r\n",
    "            ex=X[i][j] * beta[j]\r\n",
    "            expon[i] = ex + expon[i]\r\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\r\n",
    "            pi[i]=1/(1+np.exp(-expon[i]))\r\n",
    "    return pi"
   ]
  },
  {
   "source": [
    "### Calcular la matriz diagonal W\n",
    "\n",
    "$$W = diag(P_i \\cdot (1-P_1))_{i=1}^n$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def findW(pi):\n",
    "    import numpy as np\n",
    "    n = len(pi)\n",
    "    W = np.zeros(n*n).reshape(n,n)\n",
    "\n",
    "    for i in range(n):\n",
    "        W[i,i]=pi[i]*(1-pi[i])\n",
    "        W[i,i].astype(float)\n",
    "    return W"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "### Obtener la solución de la Función Logística\n",
    "$$\\beta_{n+1} = \\beta_n - \\frac{f(\\beta_n)}{f'(\\beta_n)}$$\n",
    "$$f(\\beta) = X(Y-P)$$\n",
    "$$f'(\\beta) = XWX^T$$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistics(X, Y, limit):\n",
    "    import numpy as np\n",
    "    from numpy import linalg\n",
    "    n_rows = np.shape(X)[0]\n",
    "    bias = np.ones(n_rows).reshape(n_rows, 1)\n",
    "    X_new = np.append(X, bias, axis = 1)\n",
    "    n_cols = np.shape(X_new)[1]\n",
    "\n",
    "    beta = np.zeros(n_cols).reshape(n_cols, 1)\n",
    "    root_dif = np.array(range(1,n_cols+1)).reshape(n_cols, 1)\n",
    "    iter_i = 10000\n",
    "    # El limite es de la dif de cambio\n",
    "    while (iter_i > limit):\n",
    "        print(iter_i, \", \", limit)\n",
    "        pi = logitprobs(X_new, beta)\n",
    "        print(pi)\n",
    "        W = findW(pi)\n",
    "        print(W)\n",
    "\n",
    "        num = (np.transpose(np.matrix(X_new))*np.matrix(Y - np.transpose(pi)).transpose())\n",
    "        den = (np.matrix(np.transpose(X_new))*np.matrix(W)*np.matrix(X_new))\n",
    "        root_dif = np.array(linalg.inv(den)*num)\n",
    "        print(\"Beta: \",beta, \"\\n Iter: \", iter_i)\n",
    "        beta = beta + root_dif\n",
    "        iter_i = np.sum(root_dif * root_dif)\n",
    "        ll = likelihood(Y, pi)\n",
    "    return beta"
   ]
  },
  {
   "source": [
    "## Comprobación experimental"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(range(10)).reshape(10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [0,0,0,0,1,0,1,0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = np.ones(10).reshape(10,1)\n",
    "X_new = np.append(X,bias,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 1.],\n",
       "       [2., 1.],\n",
       "       [3., 1.],\n",
       "       [4., 1.],\n",
       "       [5., 1.],\n",
       "       [6., 1.],\n",
       "       [7., 1.],\n",
       "       [8., 1.],\n",
       "       [9., 1.]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10000 ,  1e-05\n[array([0.5]), array([0.5]), array([0.5]), array([0.5]), array([0.5]), array([0.5]), array([0.5]), array([0.5]), array([0.5]), array([0.5])]\n[[0.25 0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n [0.   0.25 0.   0.   0.   0.   0.   0.   0.   0.  ]\n [0.   0.   0.25 0.   0.   0.   0.   0.   0.   0.  ]\n [0.   0.   0.   0.25 0.   0.   0.   0.   0.   0.  ]\n [0.   0.   0.   0.   0.25 0.   0.   0.   0.   0.  ]\n [0.   0.   0.   0.   0.   0.25 0.   0.   0.   0.  ]\n [0.   0.   0.   0.   0.   0.   0.25 0.   0.   0.  ]\n [0.   0.   0.   0.   0.   0.   0.   0.25 0.   0.  ]\n [0.   0.   0.   0.   0.   0.   0.   0.   0.25 0.  ]\n [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.25]]\nBeta:  [[0.]\n [0.]] \n Iter:  10000\n5.777190082644626 ,  1e-05\n[array([0.08598797]), array([0.12705276]), array([0.18378532]), array([0.2583532]), array([0.35019508]), array([0.45467026]), array([0.56329497]), array([0.66616913]), array([0.75533524]), array([0.82687453])]\n[[0.07859404 0.         0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.11091035 0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.15000827 0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.19160683 0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.22755849 0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.24794521\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.24599375 0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.22238782 0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.18480392 0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.14315304]]\nBeta:  [[ 0.43636364]\n [-2.36363636]] \n Iter:  5.777190082644626\n0.9940407075349107 ,  1e-05\n[array([0.0340128]), array([0.06053134]), array([0.10546805]), array([0.1774629]), array([0.28305225]), array([0.41943069]), array([0.56933774]), array([0.7075284]), array([0.81572841]), array([0.89011647])]\n[[0.03285593 0.         0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.0568673  0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.09434454 0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.14596982 0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.20293367 0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.24350859\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.24519228 0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.20693196 0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.15031557 0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.09780914]]\nBeta:  [[ 0.60426056]\n [-3.34641372]] \n Iter:  0.9940407075349107\n0.10600674406802027 ,  1e-05\n[array([0.02490177]), array([0.04697681]), array([0.0868775]), array([0.15515129]), array([0.26170168]), array([0.40624059]), array([0.56907679]), array([0.71823018]), array([0.83108181]), array([0.90473054])]\n[[0.02428167 0.         0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.04476999 0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.0793298  0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.13107937 0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.19321391 0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.24120917\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.2452284  0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.20237559 0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.14038483 0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.08619319]]\nBeta:  [[ 0.65761412]\n [-3.66759924]] \n Iter:  0.10600674406802027\n0.0007928351246008561 ,  1e-05\n[array([0.02423594]), array([0.04594805]), array([0.08540873]), array([0.15331276]), array([0.25986436]), array([0.40504298]), array([0.56897776]), array([0.71907124]), array([0.83230289]), array([0.90586963])]\n[[0.02364856 0.         0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.04383683 0.         0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.07811408 0.         0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.12980796 0.         0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.19233487 0.\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.24098316\n  0.         0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.24524207 0.         0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.20200779 0.         0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.13957479 0.        ]\n [0.         0.         0.         0.         0.         0.\n  0.         0.         0.         0.08526985]]\nBeta:  [[ 0.66217766]\n [-3.6953843 ]] \n Iter:  0.0007928351246008561\n"
     ]
    }
   ],
   "source": [
    "a = logistics(X,Y,0.00001)"
   ]
  },
  {
   "source": [
    "# Con el paquete Stats"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model = sm.Logit(Y,X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimization terminated successfully.\n         Current function value: 0.431012\n         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "result = logit_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                           Logit Regression Results                           \n==============================================================================\nDep. Variable:                      y   No. Observations:                   10\nModel:                          Logit   Df Residuals:                        8\nMethod:                           MLE   Df Model:                            1\nDate:                Tue, 05 Jan 2021   Pseudo R-squ.:                  0.3596\nTime:                        12:07:18   Log-Likelihood:                -4.3101\nconverged:                       True   LL-Null:                       -6.7301\nCovariance Type:            nonrobust   LLR p-value:                   0.02781\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nx1             0.6622      0.400      1.655      0.098      -0.122       1.446\nconst         -3.6956      2.289     -1.615      0.106      -8.182       0.791\n============================================================================== \n\n                         Results: Logit\n===============================================================\nModel:              Logit            Pseudo R-squared: 0.360   \nDependent Variable: y                AIC:              12.6202 \nDate:               2021-01-05 12:07 BIC:              13.2254 \nNo. Observations:   10               Log-Likelihood:   -4.3101 \nDf Model:           1                LL-Null:          -6.7301 \nDf Residuals:       8                LLR p-value:      0.027807\nConverged:          1.0000           Scale:            1.0000  \nNo. Iterations:     6.0000                                     \n-----------------------------------------------------------------\n          Coef.    Std.Err.      z      P>|z|     [0.025   0.975]\n-----------------------------------------------------------------\nx1        0.6622     0.4001    1.6551   0.0979   -0.1220   1.4464\nconst    -3.6956     2.2889   -1.6145   0.1064   -8.1818   0.7906\n===============================================================\n\n"
     ]
    }
   ],
   "source": [
    "print(result.summary(),\"\\n\\n\",result.summary2())"
   ]
  }
 ]
}